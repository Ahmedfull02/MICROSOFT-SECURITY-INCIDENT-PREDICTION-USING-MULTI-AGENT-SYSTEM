{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8929038,"sourceType":"datasetVersion","datasetId":5371198}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"name":"Practica-SIGE","provenance":[],"include_colab_link":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Ahmedfull02/MICROSOFT-SECURITY-INCIDENT-PREDICTION-USING-MULTI-AGENT-SYSTEM/blob/master/Practica_SIGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# 0.Download necessary files","metadata":{"id":"eDyKsjE0zPmz"}},{"cell_type":"markdown","source":"## 0.1 Downloading Dataset","metadata":{"id":"Wr9-2pT9zBSI"}},{"cell_type":"code","source":"# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n# THEN FEEL FREE TO DELETE THIS CELL.\n# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n# NOTEBOOK.\nimport kagglehub\nmicrosoft_microsoft_security_incident_prediction_path = kagglehub.dataset_download('Microsoft/microsoft-security-incident-prediction')\n# if microsoft_microsoft_security_incident_prediction_path == '/kaggle/input/microsoft-security-incident-prediction':\nprint('Data source import complete.')\n# else :\n#   print('Data source import failed.will retry one more time')\n#   microsoft_microsoft_security_incident_prediction_path = kagglehub.dataset_download('Microsoft/microsoft-security-incident-prediction')","metadata":{"id":"Ggm4JGTDPD2f","outputId":"26f79912-f978-4fac-84cd-e3255752cb42","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:13:52.350015Z","iopub.execute_input":"2025-06-26T21:13:52.350364Z","iopub.status.idle":"2025-06-26T21:13:53.026333Z","shell.execute_reply.started":"2025-06-26T21:13:52.350339Z","shell.execute_reply":"2025-06-26T21:13:53.025512Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 0.2 Downloading libraries","metadata":{"id":"LV0PpMEDzdz0"}},{"cell_type":"code","source":"# !pip install pandas matplotlib seaborn numpy scikit-learn catboost","metadata":{"id":"0BJMTQvBzonP","outputId":"0f286e49-901b-42e7-bd8e-c0ff05f67ace","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:13:53.027917Z","iopub.execute_input":"2025-06-26T21:13:53.028265Z","iopub.status.idle":"2025-06-26T21:13:53.034792Z","shell.execute_reply.started":"2025-06-26T21:13:53.028237Z","shell.execute_reply":"2025-06-26T21:13:53.033072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:13:53.036307Z","iopub.execute_input":"2025-06-26T21:13:53.036740Z","iopub.status.idle":"2025-06-26T21:13:53.059088Z","shell.execute_reply.started":"2025-06-26T21:13:53.036705Z","shell.execute_reply":"2025-06-26T21:13:53.058026Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MICROSOFT SECURITY INCIDENT PREDICTION USING MULTI AGENT SYSTEM\n","metadata":{"id":"Q3fxx3MAPD2k"}},{"cell_type":"markdown","source":"# 1. Environment Setup","metadata":{"id":"8D6WxOM7PD2n"}},{"cell_type":"markdown","source":"## 1.1. Imports","metadata":{"id":"qaZCvTNlPD2q"}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","metadata":{"trusted":true,"id":"AlYTUQS8PD2r","execution":{"iopub.status.busy":"2025-06-26T21:13:53.062523Z","iopub.execute_input":"2025-06-26T21:13:53.062882Z","iopub.status.idle":"2025-06-26T21:13:57.867579Z","shell.execute_reply.started":"2025-06-26T21:13:53.062852Z","shell.execute_reply":"2025-06-26T21:13:57.866487Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2. Plot Styling","metadata":{"id":"EAgQ4JdzPD2s"}},{"cell_type":"code","source":"def style_and_save(\n    ax,\n    title='',\n    xlabel='',\n    ylabel='',\n    filename='plot.png',\n    title_pad=20,\n    xlabel_pad=15,\n    ylabel_pad=15,\n    xtick_rotation=0,\n    ytick_rotation=0,\n    grid_axis='y',\n    fontsize=11,\n    show_legend=True\n):\n    ax.set_title(title, fontsize=12, fontweight='bold', pad=title_pad)\n    ax.set_xlabel(xlabel, fontsize=10, fontweight='semibold', labelpad=xlabel_pad)\n    ax.set_ylabel(ylabel, fontsize=10, fontweight='semibold', labelpad=ylabel_pad)\n    ax.tick_params(axis='x', labelrotation=xtick_rotation, labelsize=fontsize)\n    ax.tick_params(axis='y', labelrotation=ytick_rotation, labelsize=fontsize)\n    ax.grid(axis=grid_axis, linestyle='--', alpha=0.5)\n    if show_legend:\n        ax.legend(loc='lower right', fontsize=10)\n    plt.tight_layout()\n    plt.savefig(filename, dpi=300)\n    plt.show()","metadata":{"trusted":true,"id":"NfBSH3FpPD2u","execution":{"iopub.status.busy":"2025-06-26T21:13:57.868599Z","iopub.execute_input":"2025-06-26T21:13:57.869104Z","iopub.status.idle":"2025-06-26T21:13:57.876844Z","shell.execute_reply.started":"2025-06-26T21:13:57.869079Z","shell.execute_reply":"2025-06-26T21:13:57.875842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_count_plot(\n    df,\n    column,\n    title='',\n    xlabel='',\n    ylabel='',\n    filename='count_plot.png',\n    order=None,\n    xtick_rotation=0,\n    annotate_values=False,\n    figsize=(8, 5)\n):\n    plt.figure(figsize=figsize)\n    ax = sns.countplot(\n        data=df[df[column].notnull()],\n        x=column,\n        order=order,\n        edgecolor='gray',\n        palette='pastel'\n    )\n\n    if annotate_values:\n        for bar in ax.patches:\n            height = bar.get_height()\n            ax.annotate(f'{height:,}',\n                        (bar.get_x() + bar.get_width() / 2., height),\n                        ha='center', va='bottom', fontsize=10, fontweight='semibold')\n\n    style_and_save(\n        ax,\n        title=title,\n        xlabel=xlabel,\n        ylabel=ylabel,\n        filename=filename,\n        xtick_rotation=xtick_rotation\n    )\n","metadata":{"trusted":true,"id":"bTBlVcNCPD2w","execution":{"iopub.status.busy":"2025-06-26T21:13:57.878091Z","iopub.execute_input":"2025-06-26T21:13:57.878371Z","iopub.status.idle":"2025-06-26T21:13:57.924328Z","shell.execute_reply.started":"2025-06-26T21:13:57.878341Z","shell.execute_reply":"2025-06-26T21:13:57.923407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_stacked_barh(\n    df,\n    title='',\n    xlabel='',\n    ylabel='',\n    filename='stacked_barh.png',\n    colors=None,\n    figsize=(10, 6),\n    annotate_values=False\n):\n    if colors is None:\n        colors = sns.color_palette('pastel')[:df.shape[1]]\n\n    ax = df.plot(\n        kind='barh',\n        stacked=True,\n        figsize=figsize,\n        color=colors,\n        edgecolor='gray'\n    )\n\n    if annotate_values:\n        for container in ax.containers:\n            for bar in container:\n                width = bar.get_width()\n                if width > 0:\n                    ax.text(\n                        bar.get_x() + width / 2,\n                        bar.get_y() + bar.get_height() / 2,\n                        f'{int(width):,}',\n                        ha='center', va='center',\n                        fontsize=9\n                    )\n\n    style_and_save(\n        ax,\n        title=title,\n        xlabel=xlabel,\n        ylabel=ylabel,\n        filename=filename,\n        grid_axis='x'\n    )","metadata":{"trusted":true,"id":"PuedpHyiPD2x","execution":{"iopub.status.busy":"2025-06-26T21:13:57.925155Z","iopub.execute_input":"2025-06-26T21:13:57.925442Z","iopub.status.idle":"2025-06-26T21:13:57.945756Z","shell.execute_reply.started":"2025-06-26T21:13:57.925414Z","shell.execute_reply":"2025-06-26T21:13:57.944547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3. Dataset Loading","metadata":{"id":"GTgk9riWPD2z"}},{"cell_type":"code","source":"# DO NOT IMPORT DATASET WITH THIS LINE IF YOU HAVE LIMITED RAM IN COLAB\n#df = pd.read_csv('/kaggle/input/microsoft-security-incident-prediction/GUIDE_Train.csv')","metadata":{"trusted":true,"id":"2xskHvbSPD20","execution":{"iopub.status.busy":"2025-06-26T21:13:57.947119Z","iopub.execute_input":"2025-06-26T21:13:57.947486Z","iopub.status.idle":"2025-06-26T21:13:57.967064Z","shell.execute_reply.started":"2025-06-26T21:13:57.947457Z","shell.execute_reply":"2025-06-26T21:13:57.965866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# RUN THIS INSTEAD\nchunks = pd.read_csv('/kaggle/input/microsoft-security-incident-prediction/GUIDE_Train.csv',chunksize=5000)\ndf = pd.concat(chunks)","metadata":{"id":"9wJA95mw2oc5","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:13:57.968313Z","iopub.execute_input":"2025-06-26T21:13:57.968581Z","iopub.status.idle":"2025-06-26T21:15:31.544371Z","shell.execute_reply.started":"2025-06-26T21:13:57.968560Z","shell.execute_reply":"2025-06-26T21:15:31.543308Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis","metadata":{"id":"2jjOXbo_PD28"}},{"cell_type":"markdown","source":"### 2.1. Dataset Definition","metadata":{"id":"2cwfxnNCPD29"}},{"cell_type":"markdown","source":"#### 2.1.1. Columns","metadata":{"id":"fICbAT2DPD2-"}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"id":"BCWS71vEPD2-","outputId":"2ea28220-57a4-4ff6-93c6-14b6e9bb9934","execution":{"iopub.status.busy":"2025-06-26T21:15:31.548131Z","iopub.execute_input":"2025-06-26T21:15:31.548524Z","iopub.status.idle":"2025-06-26T21:15:31.579408Z","shell.execute_reply.started":"2025-06-26T21:15:31.548499Z","shell.execute_reply":"2025-06-26T21:15:31.578230Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.1.1. Variables (Columns)\n\n| Feature               | Description |\n|-----------------------|------------|\n| Id                    | Unique identifier for each OrgId-IncidentId combination, ensuring global uniqueness of each record |\n| OrgId                 | Identifier for the organization where the incident or alert originated (used to separate data across tenants) |\n| IncidentId            | Unique identifier assigned by the organization to each tracked security incident |\n| AlertId               | Unique identifier for an individual alert generated by a detection system |\n| Timestamp             | Date and time when the alert was created (UTC format) |\n| DetectorId            | Identifier of the detection engine that generated the alert |\n| AlertTitle            | Descriptive title summarizing the nature of the alert |\n| Category              | Broad classification of the alert (type of detected threat) |\n| MitreTechniques       | List of MITRE ATT&CK techniques associated with the alert |\n| IncidentGrade         | Severity level assigned by the Security Operations Center |\n| ActionGrouped         | High-level description of the remediation action taken |\n| ActionGranular        | Detailed description of the specific remediation measures |\n| EntityType            | Type of entity involved in the alert |\n| EvidenceRole          | Role of the evidence within the investigation |\n| Roles                 | Additional metadata labels for entity roles in the alert |\n| DeviceId              | Unique identifier for the device involved |\n| DeviceName            | Human-readable name of the device involved |\n| Sha256                | SHA-256 hash of the file involved |\n| IpAddress             | IP address associated with the alert |\n| Url                   | URL involved in the alert |\n| AccountSid            | Identifier for an on-premises account linked to the alert |\n| AccountUpn            | User Principal Name of the account involved |\n| AccountObjectId       | Entra ID object identifier for the user/account |\n| AccountName           | Username of the on-premises account involved |\n| NetworkMessageId      | Organization-level unique identifier for email messages |\n| EmailClusterId        | Identifier for a cluster of related email messages |\n| RegistryKey           | Windows registry key involved |\n| RegistryValueName     | Name of the registry value that was modified/accessed |\n| RegistryValueData     | Data stored in the registry value at alert time |\n| ApplicationId         | Unique identifier for an application involved |\n| ApplicationName       | Name of the application involved |\n| OAuthApplicationId    | Identifier for the OAuth application involved |\n| ThreatFamily          | Name of the detected malware family |\n| FileName              | Name of the file involved |\n| FolderPath            | Path where the file was located at alert time |\n| ResourceIdName        | Name of the Azure resource involved |\n| ResourceType          | Type of Azure resource involved |\n| OSFamily              | Operating system family of the device |\n| OSVersion             | Operating system version of the device |\n| AntispamDirection     | Direction of email traffic processed by antispam |\n| SuspicionLevel        | Assigned level of suspicion for the alert/entity |\n| LastVerdict           | Final classification after review |\n| CountryCode           | ISO country code of the alert's geographic location |\n| State                 | State/province name of the alert evidence location |\n| City                  | City name of the alert evidence location |","metadata":{"id":"zX40FIUEPD2-"}},{"cell_type":"markdown","source":"### 2.1.2. Entries","metadata":{"id":"7GSZfc0-PD2_"}},{"cell_type":"code","source":"total_rows = len(df)\nprint(f\"{total_rows:,}\")","metadata":{"trusted":true,"id":"Xyv5lB9sPD2_","outputId":"b33f9843-9d65-48ad-ab17-718379cd8c16","execution":{"iopub.status.busy":"2025-06-26T21:15:31.580409Z","iopub.execute_input":"2025-06-26T21:15:31.580741Z","iopub.status.idle":"2025-06-26T21:15:31.606922Z","shell.execute_reply.started":"2025-06-26T21:15:31.580715Z","shell.execute_reply":"2025-06-26T21:15:31.605779Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2. Target Variable Selection","metadata":{"id":"bCBBy-oIPD2_"}},{"cell_type":"code","source":"candidates_var = ['IncidentGrade', 'SuspicionLevel', 'LastVerdict', 'Category']\n\nfor col in candidates_var:\n    print(f\"\\n📌 Variable: {col}\")\n    print(\"-\" * 40)\n    print(f\"Unique values:\\n{df[col].unique()}\")\n    print(f\"\\nnumber of NULL values: {df[col].isnull().sum()} de {len(df)} registros totales\")\n    print(\"=\" * 60)","metadata":{"trusted":true,"id":"dOGfo7LgPD3A","outputId":"7825dec0-b4d8-4c77-9806-7ddbc9688819","execution":{"iopub.status.busy":"2025-06-26T21:15:31.608417Z","iopub.execute_input":"2025-06-26T21:15:31.608762Z","iopub.status.idle":"2025-06-26T21:15:34.807688Z","shell.execute_reply.started":"2025-06-26T21:15:31.608729Z","shell.execute_reply":"2025-06-26T21:15:34.806697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vars = ['IncidentGrade', 'SuspicionLevel', 'LastVerdict', 'Category']\n\n# Calculation of null and non-null values\n\ndata = {\n    'Not Null': [df[var].notnull().sum() for var in vars],\n    'Null': [df[var].isnull().sum() for var in vars]\n}\n\n# DataFrame creation\n\ndf_nulls = pd.DataFrame(data, index=vars)\n\n# Plot\n\ncreate_stacked_barh(\n    df=df_nulls,\n    title='Null vs Non-Null Values by Candidate Variable',\n    xlabel='Record Count',\n    ylabel='Variable',\n    filename='null_values_by_variable.png',\n    annotate_values=False\n)\n","metadata":{"trusted":true,"id":"p6_ILug3PD3A","outputId":"7922fa10-9551-4724-842a-99a0b7119d92","execution":{"iopub.status.busy":"2025-06-26T21:15:34.808729Z","iopub.execute_input":"2025-06-26T21:15:34.809014Z","iopub.status.idle":"2025-06-26T21:15:38.797095Z","shell.execute_reply.started":"2025-06-26T21:15:34.808984Z","shell.execute_reply":"2025-06-26T21:15:38.795984Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3. Target Variable Distribution","metadata":{"id":"jLqIU68jPD3B"}},{"cell_type":"code","source":"create_count_plot(\n    df=df,\n    column='IncidentGrade',\n    title='Target Variable Distribution: IncidentGrade',\n    xlabel='Severity Class',\n    ylabel='Record Count',\n    filename='target_variable_distribution.png',\n    order=df['IncidentGrade'].value_counts().index,\n    figsize=(16,9)\n)","metadata":{"trusted":true,"id":"617XqncwPD3B","execution":{"iopub.status.busy":"2025-06-26T21:15:38.797787Z","iopub.execute_input":"2025-06-26T21:15:38.798054Z","iopub.status.idle":"2025-06-26T21:15:47.267718Z","shell.execute_reply.started":"2025-06-26T21:15:38.798034Z","shell.execute_reply":"2025-06-26T21:15:47.266631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.4. Missing Values Visualization","metadata":{"id":"tOlu0iooPD3C"}},{"cell_type":"code","source":"# Count null values per column\n\nmissing_values = df.isnull().sum()\nmissing_values = missing_values[missing_values > 0]\nmissing_values = missing_values.sort_values()\n\n# Visualize\n\nplt.figure(figsize=(12, 6))\nmissing_values.plot(kind='barh', color='skyblue')\nplt.title('Number of missing values per column')\nplt.xlabel('Null count')\nplt.ylabel('Columns')\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.show()","metadata":{"trusted":true,"id":"IGWN3bUkPD3C","outputId":"cada623c-224e-4284-e55f-f05c7554ef1c","execution":{"iopub.status.busy":"2025-06-26T21:15:47.269051Z","iopub.execute_input":"2025-06-26T21:15:47.269308Z","iopub.status.idle":"2025-06-26T21:15:53.080135Z","shell.execute_reply.started":"2025-06-26T21:15:47.269289Z","shell.execute_reply":"2025-06-26T21:15:53.079081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Preprocessing","metadata":{"id":"y5iLz-AQPD3D"}},{"cell_type":"markdown","source":"## 3.1. Data Cleaning","metadata":{"id":"2cwQwmxKPD3D"}},{"cell_type":"markdown","source":"### 3.1.1. Dropping Rows/Columns with Null Values","metadata":{"id":"PPs3gpfH69Wr"}},{"cell_type":"code","source":"def viewRemainingColumns():\n    numeric_columns = df.select_dtypes(include=['float64', 'int64', 'int32']).columns\n    string_columns = df.select_dtypes(include=['object']).columns\n\n    # Print column names\n    print(\"Numeric columns:\")\n    print(numeric_columns)\n    print(f\"Total of Numeric columns: {len(numeric_columns)}\\n\")\n\n    print(\"String columns:\")\n    print(string_columns)\n    print(f\"Total of String columns: {len(string_columns)}\")","metadata":{"trusted":true,"id":"r_OFnsTsPD3D","execution":{"iopub.status.busy":"2025-06-26T21:15:53.081588Z","iopub.execute_input":"2025-06-26T21:15:53.081890Z","iopub.status.idle":"2025-06-26T21:15:53.088347Z","shell.execute_reply.started":"2025-06-26T21:15:53.081868Z","shell.execute_reply":"2025-06-26T21:15:53.087225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop columns with more than 70% null values\n\ncolumns_with_high_null = []\n\nfor column in df.columns:\n    if df[column].isnull().sum() / total_rows > 0.7:\n        columns_with_high_null.append(column)\n\nprint(\"Columns with >70% null values:\", columns_with_high_null)\nprint(f\"Total columns to drop: {len(columns_with_high_null)}\\n\")\n\ndf = df.drop(columns=columns_with_high_null)","metadata":{"trusted":true,"id":"s_cbSGoqPD3E","outputId":"66d741ca-733a-4acb-e807-ca068f501b2e","execution":{"iopub.status.busy":"2025-06-26T21:15:53.089455Z","iopub.execute_input":"2025-06-26T21:15:53.089802Z","iopub.status.idle":"2025-06-26T21:16:00.172224Z","shell.execute_reply.started":"2025-06-26T21:15:53.089773Z","shell.execute_reply":"2025-06-26T21:16:00.171014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"viewRemainingColumns()","metadata":{"trusted":true,"id":"6zoNQ9srPD3E","execution":{"iopub.status.busy":"2025-06-26T21:16:00.173604Z","iopub.execute_input":"2025-06-26T21:16:00.173918Z","iopub.status.idle":"2025-06-26T21:16:06.186139Z","shell.execute_reply.started":"2025-06-26T21:16:00.173886Z","shell.execute_reply":"2025-06-26T21:16:06.185037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop rows with null IncidentGrade to avoid fabricating target class values\n\ndf = df.dropna(subset=['IncidentGrade'])\n\ntotal_rows_after_delete = len(df)\nprint(f\"{round((total_rows_after_delete / total_rows * 100), 2)}%\")","metadata":{"trusted":true,"id":"d_8s5oPOPD3F","execution":{"iopub.status.busy":"2025-06-26T21:16:06.187314Z","iopub.execute_input":"2025-06-26T21:16:06.187680Z","iopub.status.idle":"2025-06-26T21:16:08.698383Z","shell.execute_reply.started":"2025-06-26T21:16:06.187648Z","shell.execute_reply":"2025-06-26T21:16:08.697463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Update total row count after cleaning\ntotal_rows = total_rows_after_delete\nprint(f\"Updated dataset contains {total_rows:,} records\")","metadata":{"trusted":true,"id":"svyW9ZeePD3F","execution":{"iopub.status.busy":"2025-06-26T21:16:08.699680Z","iopub.execute_input":"2025-06-26T21:16:08.700057Z","iopub.status.idle":"2025-06-26T21:16:08.706648Z","shell.execute_reply.started":"2025-06-26T21:16:08.700028Z","shell.execute_reply":"2025-06-26T21:16:08.705372Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.1.2. Null value Removing","metadata":{"id":"diKUW809PD3G"}},{"cell_type":"code","source":"# Remove missing MitreTechniques values with the mode (most frequent value)\n\nprint(df['MitreTechniques'].isnull().sum())\n\nmode = df['MitreTechniques'].mode()[0]\n\ndf.fillna({'MitreTechniques': mode}, inplace=True)\n\nprint(df['MitreTechniques'].isnull().sum())","metadata":{"trusted":true,"id":"c_0f2NZwPD3G","execution":{"iopub.status.busy":"2025-06-26T21:16:08.707805Z","iopub.execute_input":"2025-06-26T21:16:08.708087Z","iopub.status.idle":"2025-06-26T21:16:10.905991Z","shell.execute_reply.started":"2025-06-26T21:16:08.708067Z","shell.execute_reply":"2025-06-26T21:16:10.905022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.1.3. Remove irrelevant columns","metadata":{"id":"oHKfwlmlPD3G"}},{"cell_type":"code","source":"def format_percentage(num_uniques, total_rows):\n    percentage = (num_uniques / total_rows) * 100\n    rounded = round(percentage, 2)\n    return \"<0.01%\" if rounded == 0.0 and num_uniques > 0 else f\"{rounded:.2f}%\"","metadata":{"trusted":true,"id":"_sCK96wcPD3H","execution":{"iopub.status.busy":"2025-06-26T21:16:10.906999Z","iopub.execute_input":"2025-06-26T21:16:10.907286Z","iopub.status.idle":"2025-06-26T21:16:10.912371Z","shell.execute_reply.started":"2025-06-26T21:16:10.907264Z","shell.execute_reply":"2025-06-26T21:16:10.911322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_uniques_list(cols):\n    return sorted(\n        [(col, df[col].nunique()) for col in cols],\n        key=lambda x: x[1],\n        reverse=True)\n","metadata":{"trusted":true,"id":"3CpIoNIOPD3I","execution":{"iopub.status.busy":"2025-06-26T21:16:10.913334Z","iopub.execute_input":"2025-06-26T21:16:10.913661Z","iopub.status.idle":"2025-06-26T21:16:10.936333Z","shell.execute_reply.started":"2025-06-26T21:16:10.913633Z","shell.execute_reply":"2025-06-26T21:16:10.935140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check uniqueness of ID records\n\nnumeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\nstring_cols = df.select_dtypes(include=['object']).columns\n\nnumeric_uniques = get_uniques_list(numeric_cols)\nstring_uniques = get_uniques_list(string_cols)\n\nprint(\"\\nUnique values for each numeric column:\\n\")\nprint(f\"{'Column':<30} {'Unique':<10} {'% of total'}\")\nprint(\"-\" * 55)\nfor col, num_uniques in numeric_uniques:\n    percentage_str = format_percentage(num_uniques, total_rows)\n    print(f\"{col:<30} {num_uniques:<10} {percentage_str}\")\n\nprint(\"\\n\\nUnique values for each categorical column:\\n\")\nprint(f\"{'Column':<30} {'Unique':<10} {'% of total'}\")\nprint(\"-\" * 55)\nfor col, num_uniques in string_uniques:\n    percentage_str = format_percentage(num_uniques, total_rows)\n    print(f\"{col:<30} {num_uniques:<10} {percentage_str}\")\n","metadata":{"trusted":true,"id":"Xtn6adRKPD3I","execution":{"iopub.status.busy":"2025-06-26T21:16:10.937207Z","iopub.execute_input":"2025-06-26T21:16:10.937527Z","iopub.status.idle":"2025-06-26T21:16:25.695815Z","shell.execute_reply.started":"2025-06-26T21:16:10.937496Z","shell.execute_reply":"2025-06-26T21:16:25.694822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of irrelevant columns for the correlation matrix\n# Selection based on previous output (>3%)\nirrelevant_columns = ['AlertId', 'Id', 'AccountUpn', 'IncidentId', 'NetworkMessageId',\n                     'AccountName', 'AccountSid', 'AccountObjectId', 'IpAddress']\n\ndf = df.drop(columns=irrelevant_columns)\n\nviewRemainingColumns()","metadata":{"trusted":true,"id":"_4QZweutPD3J","execution":{"iopub.status.busy":"2025-06-26T21:16:25.696900Z","iopub.execute_input":"2025-06-26T21:16:25.697233Z","iopub.status.idle":"2025-06-26T21:16:31.433038Z","shell.execute_reply.started":"2025-06-26T21:16:25.697202Z","shell.execute_reply":"2025-06-26T21:16:31.432018Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2. Encoding of categorical variables","metadata":{"id":"TzSCr6OVPD3J"}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Select object-type columns excluding 'Timestamp'\nencode_label = df.select_dtypes([object]).columns\nencode_label = [col for col in encode_label if col != 'Timestamp']\n\nprint(encode_label)\n\n# Dictionary to store fitted encoders\nlabel_encoders = {}\n\n# Apply LabelEncoder to each categorical column (excluding 'Timestamp')\nfor col in encode_label:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le\n","metadata":{"trusted":true,"id":"wo0OjshNPD3K","execution":{"iopub.status.busy":"2025-06-26T21:16:31.434101Z","iopub.execute_input":"2025-06-26T21:16:31.434322Z","iopub.status.idle":"2025-06-26T21:16:43.679683Z","shell.execute_reply.started":"2025-06-26T21:16:31.434304Z","shell.execute_reply":"2025-06-26T21:16:43.678394Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3. Date/Time Processing","metadata":{"id":"jWdD4WAXPD3L"}},{"cell_type":"markdown","source":"#### 3.3.1. DateTime Conversion","metadata":{"id":"-p_7aFDTPD3M"}},{"cell_type":"code","source":"### 3.3.2. Date Aggregation\n\nunique_lengths = set(df['Timestamp'].map(len))\nprint(unique_lengths)\n\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n\ndf['Year'] = df['Timestamp'].dt.year\ndf['Month'] = df['Timestamp'].dt.month\ndf['Day'] = df['Timestamp'].dt.day\ndf['Hour'] = df['Timestamp'].dt.hour\ndf['Minute'] = df['Timestamp'].dt.minute\ndf['Second'] = df['Timestamp'].dt.second\ndf['Weekday'] = df['Timestamp'].dt.weekday  # 0 = Monday, 6 = Sunday","metadata":{"trusted":true,"id":"v9PbmN-jPD3M","execution":{"iopub.status.busy":"2025-06-26T21:16:43.680553Z","iopub.execute_input":"2025-06-26T21:16:43.680838Z","iopub.status.idle":"2025-06-26T21:16:59.726231Z","shell.execute_reply.started":"2025-06-26T21:16:43.680817Z","shell.execute_reply":"2025-06-26T21:16:59.725356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3.2. Date Aggregation","metadata":{"id":"RA4HOh-WPD3M"}},{"cell_type":"code","source":"## Day: 0 | Night: 1\n\ndef asign_period(hour):\n    if 7 <= hour < 19:\n        return 0\n    else:\n        return 1\n\n\n## Spring: 0 | Summer: 1 | Autumn: 2 | Winter: 3\n\ndef asign_season(month):\n    if 3 <= month <= 5:\n        return 0\n    elif 6 <= month <= 8:\n        return 1\n    elif 9 <= month <= 11:\n        return 2\n    else:\n        return 3\n\n\n## holidays Period: 0 | Non holidays Period: 1\n\ndef asign_holidays(weekday):\n    if 0 <= weekday < 5:\n        return 0\n    else:\n        return 1","metadata":{"trusted":true,"id":"iafJHtbuPD3N","execution":{"iopub.status.busy":"2025-06-26T21:16:59.733720Z","iopub.execute_input":"2025-06-26T21:16:59.734112Z","iopub.status.idle":"2025-06-26T21:16:59.740944Z","shell.execute_reply.started":"2025-06-26T21:16:59.734087Z","shell.execute_reply":"2025-06-26T21:16:59.739943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for time slot\ndf['Period'] = df['Hour'].apply(asign_period)\n\n# For season\ndf['Season'] = df['Month'].apply(asign_season)\n\n# For Holiday\ndf['Holiday'] = df['Weekday'].apply(asign_holidays)","metadata":{"trusted":true,"id":"Oh58fLyfPD3O","execution":{"iopub.status.busy":"2025-06-26T21:16:59.751073Z","iopub.execute_input":"2025-06-26T21:16:59.751435Z","iopub.status.idle":"2025-06-26T21:17:10.593820Z","shell.execute_reply.started":"2025-06-26T21:16:59.751392Z","shell.execute_reply":"2025-06-26T21:17:10.592714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"viewRemainingColumns()","metadata":{"trusted":true,"id":"OiefB94hPD3O","execution":{"iopub.status.busy":"2025-06-26T21:17:10.597922Z","iopub.execute_input":"2025-06-26T21:17:10.598272Z","iopub.status.idle":"2025-06-26T21:17:13.269039Z","shell.execute_reply.started":"2025-06-26T21:17:10.598245Z","shell.execute_reply":"2025-06-26T21:17:13.267623Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3.3. Removal of Date Attributes","metadata":{"id":"B0U8d78rPD3P"}},{"cell_type":"code","source":"print(\"Unique values for the year:\", len(df['Year'].unique()))  # This variable can be removed","metadata":{"trusted":true,"id":"gSTEfgxcPD3P","execution":{"iopub.status.busy":"2025-06-26T21:17:13.272766Z","iopub.execute_input":"2025-06-26T21:17:13.273026Z","iopub.status.idle":"2025-06-26T21:17:13.328572Z","shell.execute_reply.started":"2025-06-26T21:17:13.273004Z","shell.execute_reply":"2025-06-26T21:17:13.327549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(columns=['Year', 'Month', 'Weekday', 'Day', 'Hour', 'Minute', 'Second'])\ndf = df.drop(columns=['Timestamp'])","metadata":{"trusted":true,"id":"VVJTaKB1PD3Q","execution":{"iopub.status.busy":"2025-06-26T21:17:13.332171Z","iopub.execute_input":"2025-06-26T21:17:13.332517Z","iopub.status.idle":"2025-06-26T21:17:14.831139Z","shell.execute_reply.started":"2025-06-26T21:17:13.332497Z","shell.execute_reply":"2025-06-26T21:17:14.830229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"viewRemainingColumns()","metadata":{"trusted":true,"id":"7IaVSeajPD3R","execution":{"iopub.status.busy":"2025-06-26T21:17:14.835176Z","iopub.execute_input":"2025-06-26T21:17:14.835524Z","iopub.status.idle":"2025-06-26T21:17:17.232603Z","shell.execute_reply.started":"2025-06-26T21:17:14.835495Z","shell.execute_reply":"2025-06-26T21:17:17.231628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.4. Correlation Analysis","metadata":{"id":"RObt39myPD3R"}},{"cell_type":"markdown","source":"### 3.4.1. Correlation Matrix","metadata":{"id":"esoBGf0gPD3S"}},{"cell_type":"code","source":"# Calculate the correlation matrix\ncorrelation_matrix = df.corr()\n\n# Visualize the correlation matrix\nplt.figure(figsize=(18, 16))\nax = sns.heatmap(correlation_matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Correlation Matrix\")\n\nstyle_and_save(\n    ax=ax,\n    title='Correlation Matrix',\n    xlabel='Variables',\n    ylabel='Variables',\n    filename='Correlation Matrix.png',\n    xtick_rotation=45,\n    ytick_rotation=45\n)","metadata":{"trusted":true,"id":"4jtTRfwpPD3T","execution":{"iopub.status.busy":"2025-06-26T21:17:17.233638Z","iopub.execute_input":"2025-06-26T21:17:17.234025Z","iopub.status.idle":"2025-06-26T21:17:44.873681Z","shell.execute_reply.started":"2025-06-26T21:17:17.233951Z","shell.execute_reply":"2025-06-26T21:17:44.872477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.4.2. Elimination of highly correlated variables","metadata":{"id":"-HTiGgHBPD3T"}},{"cell_type":"code","source":"threshold = 0.7\n\nabs_corr = correlation_matrix.abs()\nhigh_corr_pairs = []\n\nnum_cols = abs_corr.shape[1]\n\nfor i in range(num_cols):\n    for j in range(i + 1, num_cols):\n        corr_value = abs_corr.iloc[i, j]\n        if corr_value > threshold:\n            high_corr_pairs.append((abs_corr.columns[i], abs_corr.columns[j], corr_value))\n\nif high_corr_pairs:\n    print(f\"Pairs of variables with correlation greater than {threshold}:\")\n    print(f\"{'Variable 1':<20} {'Variable 2':<20} {'Correlation'}\")\n    print(\"-\" * 55)\n    for col1, col2, corr_value in high_corr_pairs:\n        print(f\"{col1:<20} {col2:<20} {corr_value:.2f}\")\nelse:\n    print(f\"There are no pairs with correlation greater than {threshold}\")","metadata":{"trusted":true,"id":"gWk0eWxOPD3T","execution":{"iopub.status.busy":"2025-06-26T21:17:44.874793Z","iopub.execute_input":"2025-06-26T21:17:44.875133Z","iopub.status.idle":"2025-06-26T21:17:44.893003Z","shell.execute_reply.started":"2025-06-26T21:17:44.875110Z","shell.execute_reply":"2025-06-26T21:17:44.892057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(columns=['Sha256', 'FileName', 'RegistryValueData', 'ApplicationName', 'OSVersion', 'City', 'State'])","metadata":{"trusted":true,"id":"Ar-jdJo2PD3U","execution":{"iopub.status.busy":"2025-06-26T21:17:44.894088Z","iopub.execute_input":"2025-06-26T21:17:44.894425Z","iopub.status.idle":"2025-06-26T21:17:45.524628Z","shell.execute_reply.started":"2025-06-26T21:17:44.894394Z","shell.execute_reply":"2025-06-26T21:17:45.523585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"viewRemainingColumns()","metadata":{"trusted":true,"id":"mil-kCGHPD3U","execution":{"iopub.status.busy":"2025-06-26T21:17:45.525884Z","iopub.execute_input":"2025-06-26T21:17:45.526258Z","iopub.status.idle":"2025-06-26T21:17:47.180838Z","shell.execute_reply.started":"2025-06-26T21:17:45.526227Z","shell.execute_reply":"2025-06-26T21:17:47.179867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.5. Manual filter","metadata":{"id":"rjeV0ZThPD3V"}},{"cell_type":"code","source":"df = df.drop(columns=['OrgId', 'DetectorId', 'DeviceId', 'ApplicationId', 'OAuthApplicationId'])","metadata":{"trusted":true,"id":"6ksUGizDPD3V","execution":{"iopub.status.busy":"2025-06-26T21:17:47.181751Z","iopub.execute_input":"2025-06-26T21:17:47.182072Z","iopub.status.idle":"2025-06-26T21:17:47.564630Z","shell.execute_reply.started":"2025-06-26T21:17:47.182041Z","shell.execute_reply":"2025-06-26T21:17:47.563493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"viewRemainingColumns()","metadata":{"trusted":true,"id":"znnrwFRQPD3V","execution":{"iopub.status.busy":"2025-06-26T21:17:47.565477Z","iopub.execute_input":"2025-06-26T21:17:47.565704Z","iopub.status.idle":"2025-06-26T21:17:48.909175Z","shell.execute_reply.started":"2025-06-26T21:17:47.565688Z","shell.execute_reply":"2025-06-26T21:17:48.908137Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.6. Anomaly Detection\n### 3.5.1. Remove Outliers\n### 3.5.2. PCA","metadata":{"id":"kG05G9jaPD3W"}},{"cell_type":"markdown","source":"# 4. Training","metadata":{"id":"8tw1mJGaPD3W"}},{"cell_type":"markdown","source":"## 4.1. Training Preparation","metadata":{"id":"da57nTPAPD3X"}},{"cell_type":"markdown","source":"### 4.1.1. Imports","metadata":{"id":"DjB62FhAPD3X"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true,"id":"GG5HHIjKPD3X","execution":{"iopub.status.busy":"2025-06-26T21:17:48.910146Z","iopub.execute_input":"2025-06-26T21:17:48.910456Z","iopub.status.idle":"2025-06-26T21:17:50.128176Z","shell.execute_reply.started":"2025-06-26T21:17:48.910429Z","shell.execute_reply":"2025-06-26T21:17:50.127207Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.1.2. Encoding of the Target Variable","metadata":{"id":"371lqmJsPD3Y"}},{"cell_type":"code","source":"label_map = {\n    'BenignPositive': 0,\n    'FalsePositive': 1,\n    'TruePositive': 2\n}","metadata":{"trusted":true,"id":"4Kf0I7iEPD3Y","execution":{"iopub.status.busy":"2025-06-26T21:17:50.129192Z","iopub.execute_input":"2025-06-26T21:17:50.129820Z","iopub.status.idle":"2025-06-26T21:17:50.135011Z","shell.execute_reply.started":"2025-06-26T21:17:50.129792Z","shell.execute_reply":"2025-06-26T21:17:50.134146Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.1.3. Data Splitting","metadata":{"id":"LG69NOKbPD3Y"}},{"cell_type":"code","source":"# X e y\nX = df.drop(columns=['IncidentGrade'])\ny = df['IncidentGrade']","metadata":{"trusted":true,"id":"TSycpXFjPD3Y","execution":{"iopub.status.busy":"2025-06-26T21:17:50.135836Z","iopub.execute_input":"2025-06-26T21:17:50.136168Z","iopub.status.idle":"2025-06-26T21:17:50.602339Z","shell.execute_reply.started":"2025-06-26T21:17:50.136140Z","shell.execute_reply":"2025-06-26T21:17:50.601345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n   X, y, test_size=0.2, random_state=42, stratify=y\n)","metadata":{"trusted":true,"id":"xB75eRQ9PD3Z","execution":{"iopub.status.busy":"2025-06-26T21:17:50.603393Z","iopub.execute_input":"2025-06-26T21:17:50.603646Z","iopub.status.idle":"2025-06-26T21:17:58.955659Z","shell.execute_reply.started":"2025-06-26T21:17:50.603628Z","shell.execute_reply":"2025-06-26T21:17:58.954579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2. Modeling","metadata":{"id":"exgjcnl7PD3Z"}},{"cell_type":"markdown","source":"### 4.2.1 Non Balanced dataset","metadata":{}},{"cell_type":"code","source":"# models = {\n#     'CatBoost': CatBoostClassifier(verbose=True),\n#     'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', verbosity=2),\n#     'RandomForest': RandomForestClassifier(verbose=2)\n# }","metadata":{"trusted":true,"id":"uAFpEIy6PD3Z","execution":{"iopub.status.busy":"2025-06-26T21:17:58.957348Z","iopub.execute_input":"2025-06-26T21:17:58.957718Z","iopub.status.idle":"2025-06-26T21:17:58.961979Z","shell.execute_reply.started":"2025-06-26T21:17:58.957692Z","shell.execute_reply":"2025-06-26T21:17:58.960841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3. Training","metadata":{"id":"ryrZtahuPD3a"}},{"cell_type":"code","source":"# for name, model in models.items():\n#    print(f\"\\Training {name}...\")\n#    model.fit(X_train, y_train)\n#    print(\"Testing...\") \n#    y_pred = model.predict(X_test)\n#    print(f\"\\n{name} Classification Report:\")\n#    print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"id":"Rv41y36GPD3a","execution":{"iopub.status.busy":"2025-06-26T21:17:58.962998Z","iopub.execute_input":"2025-06-26T21:17:58.963324Z","iopub.status.idle":"2025-06-26T21:17:58.986375Z","shell.execute_reply.started":"2025-06-26T21:17:58.963295Z","shell.execute_reply":"2025-06-26T21:17:58.985348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 Save Models as file","metadata":{}},{"cell_type":"code","source":"# import joblib\n# import os\n# # Output directory\n# output_dir = 'trained_models'\n# os.makedirs(output_dir, exist_ok=True)\n# # \n# # Save each model\n# for name, model in models.items():\n#     filename = os.path.join(output_dir, f'{name}_model.joblib')\n#     joblib.dump(model, filename)\n#     print(f\"Model '{name}' saved to '{filename}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:17:58.987450Z","iopub.execute_input":"2025-06-26T21:17:58.987766Z","iopub.status.idle":"2025-06-26T21:17:59.008782Z","shell.execute_reply.started":"2025-06-26T21:17:58.987735Z","shell.execute_reply":"2025-06-26T21:17:59.007829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.5 Load models (Optional)","metadata":{}},{"cell_type":"code","source":"# loaded_models = {}\n# for name in models.keys(): # Use the original key names for consistency\n#     filename = os.path.join(output_dir, f'{name}_model.joblib')\n#     if os.path.exists(filename):\n#         loaded_model = joblib.load(filename)\n#         loaded_models[name] = loaded_model\n#         print(f\"Model '{name}' loaded from '{filename}'\")\n#     else:\n#         print(f\"File '{filename}' not found for model '{name}'.\")\n\n# for name, model in loaded_models.items():\n#    print(\"Testing...\") \n#    y_pred = model.predict(X_test)\n#    print(f\"\\n{name} Classification Report:\")\n#    print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:17:59.009783Z","iopub.execute_input":"2025-06-26T21:17:59.010127Z","iopub.status.idle":"2025-06-26T21:17:59.034702Z","shell.execute_reply.started":"2025-06-26T21:17:59.010097Z","shell.execute_reply":"2025-06-26T21:17:59.033312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.2.2 Balanced dataset","metadata":{}},{"cell_type":"code","source":"models_balanced = {\n    'CatBoost': CatBoostClassifier(auto_class_weights='Balanced', verbose=True),\n    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', verbosity=2), # XGBoost does not have an argument to apply weighted class\n    'RandomForest': RandomForestClassifier(class_weight='balanced', verbose=2)\n}","metadata":{"trusted":true,"id":"uAFpEIy6PD3Z","execution":{"iopub.status.busy":"2025-06-26T21:17:59.035894Z","iopub.execute_input":"2025-06-26T21:17:59.036420Z","iopub.status.idle":"2025-06-26T21:17:59.058598Z","shell.execute_reply.started":"2025-06-26T21:17:59.036388Z","shell.execute_reply":"2025-06-26T21:17:59.057446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate class weight manually for XGBoost\nfrom sklearn.utils.class_weight import compute_class_weight\n\n\n# Get Classes\nclasses = np.unique(y_test)\n\nclass_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\nclass_weight_dict = dict(zip(classes, class_weights))\n\n# For XGBoost: Convert class weights to sample weights\nsample_weights = y_train.map(class_weight_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:17:59.059758Z","iopub.execute_input":"2025-06-26T21:17:59.060107Z","iopub.status.idle":"2025-06-26T21:18:00.371945Z","shell.execute_reply.started":"2025-06-26T21:17:59.060085Z","shell.execute_reply":"2025-06-26T21:18:00.371023Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3. Training","metadata":{"id":"ryrZtahuPD3a"}},{"cell_type":"code","source":"for name, model in models_balanced.items():\n    print(f\"\\Training {name}...\")\n    if name == 'XGBoost':\n        model.fit(X_train, y_train, sample_weight=sample_weights)\n    else:\n        model.fit(X_train, y_train)\n    print(\"Testing...\") \n    y_pred = model.predict(X_test)\n    print(f\"\\n{name} Classification Report:\")\n    print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"id":"Rv41y36GPD3a","execution":{"iopub.status.busy":"2025-06-26T21:18:00.372690Z","iopub.execute_input":"2025-06-26T21:18:00.372906Z","iopub.status.idle":"2025-06-26T21:18:15.492804Z","shell.execute_reply.started":"2025-06-26T21:18:00.372889Z","shell.execute_reply":"2025-06-26T21:18:15.489168Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 Save Models as file","metadata":{}},{"cell_type":"code","source":"import joblib\nimport os\n# Output directory\noutput_dir = 'trained_models_balanced'\nos.makedirs(output_dir, exist_ok=True)\n\n# Save each model\nfor name, model in models_balanced.items():\n    filename = os.path.join(output_dir, f'{name}_model.joblib')\n    joblib.dump(model, filename)\n    print(f\"Model '{name}' saved to '{filename}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.493899Z","iopub.status.idle":"2025-06-26T21:18:15.494798Z","shell.execute_reply.started":"2025-06-26T21:18:15.494552Z","shell.execute_reply":"2025-06-26T21:18:15.494575Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.5 Load models (Optional)","metadata":{}},{"cell_type":"code","source":"loaded_models_balanced = {}\nfor name in models_balanced.keys(): # Use the original key names for consistency\n    filename = os.path.join(output_dir, f'{name}_model.joblib')\n    if os.path.exists(filename):\n        loaded_model = joblib.load(filename)\n        loaded_models_balanced[name] = loaded_model\n        print(f\"Model '{name}' loaded from '{filename}'\")\n    else:\n        print(f\"File '{filename}' not found for model '{name}'.\")\n\nfor name, model in loaded_models_balanced.items():\n   print(\"Testing...\") \n   y_pred = model.predict(X_test)\n   print(f\"\\n{name} Classification Report:\")\n   print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.496432Z","iopub.status.idle":"2025-06-26T21:18:15.496746Z","shell.execute_reply.started":"2025-06-26T21:18:15.496607Z","shell.execute_reply":"2025-06-26T21:18:15.496620Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4. Class Balancing","metadata":{"id":"HkSw_b18PD3b","_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"# from imblearn.under_sampling import RandomUnderSampler\n# from imblearn.over_sampling import SMOTE\n# from imblearn.under_sampling import CondensedNearestNeighbour\n# from sklearn.utils import shuffle\n# from sklearn.cluster import KMeans\n# from sklearn.metrics import pairwise_distances_argmin_min\n# from imblearn.under_sampling import ClusterCentroids\n# from sklearn.cluster import MiniBatchKMeans\n# from sklearn.utils import resample\n# import time","metadata":{"trusted":true,"id":"vIrlaoDjPD3c","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.497777Z","iopub.status.idle":"2025-06-26T21:18:15.498170Z","shell.execute_reply.started":"2025-06-26T21:18:15.498014Z","shell.execute_reply":"2025-06-26T21:18:15.498031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# target_size = y.value_counts()[1]","metadata":{"trusted":true,"id":"jtJblQ6kPD3d","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.500309Z","iopub.status.idle":"2025-06-26T21:18:15.500723Z","shell.execute_reply.started":"2025-06-26T21:18:15.500510Z","shell.execute_reply":"2025-06-26T21:18:15.500531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 1. Undersample clase 0 (BenignPositive)\n# rus_0 = RandomUnderSampler(sampling_strategy={0: target_size}, random_state=42)\n# X_rus_0, y_rus_0 = rus_0.fit_resample(X, y)","metadata":{"trusted":true,"id":"Wn2kFEt2PD3e","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.502296Z","iopub.status.idle":"2025-06-26T21:18:15.502711Z","shell.execute_reply.started":"2025-06-26T21:18:15.502524Z","shell.execute_reply":"2025-06-26T21:18:15.502542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Oversample clase 1 (FalsePositive) based on the result of the previous step\n# smote = SMOTE(sampling_strategy={1: target_size}, random_state=42)\n# X_balanced, y_balanced = smote.fit_resample(X_rus, y_rus)","metadata":{"trusted":true,"id":"Ut8pfVMHPD3e","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.504808Z","iopub.status.idle":"2025-06-26T21:18:15.505251Z","shell.execute_reply.started":"2025-06-26T21:18:15.505041Z","shell.execute_reply":"2025-06-26T21:18:15.505061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 2. Undersample clase 2 (BenignPositive)\n# rus_2 = RandomUnderSampler(sampling_strategy={2: target_size}, random_state=42)\n# X_rus_final, y_rus_final = rus_2.fit_resample(X_rus_0, y_rus_0)","metadata":{"trusted":true,"id":"-lGgIsl0PD3f","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.505860Z","iopub.status.idle":"2025-06-26T21:18:15.506257Z","shell.execute_reply.started":"2025-06-26T21:18:15.506061Z","shell.execute_reply":"2025-06-26T21:18:15.506078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 3.  Shuffle Data\n# X_balanced, y_balanced = shuffle(X_rus_final, y_rus_final, random_state=42)","metadata":{"trusted":true,"id":"4UpO_HBcPD3g","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.507711Z","iopub.status.idle":"2025-06-26T21:18:15.508016Z","shell.execute_reply.started":"2025-06-26T21:18:15.507858Z","shell.execute_reply":"2025-06-26T21:18:15.507869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 4. Verify the Result\n# print(\"Distribution after undersampling:\")\n# print(y_balanced.value_counts())","metadata":{"trusted":true,"id":"d_oa5C4uPD3g","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.509577Z","iopub.status.idle":"2025-06-26T21:18:15.510039Z","shell.execute_reply.started":"2025-06-26T21:18:15.509811Z","shell.execute_reply":"2025-06-26T21:18:15.509828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X_train, X_test, y_train, y_test = train_test_split(\n#     X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n# )","metadata":{"trusted":true,"id":"TiG_4KcwPD3h","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.512335Z","iopub.status.idle":"2025-06-26T21:18:15.512773Z","shell.execute_reply.started":"2025-06-26T21:18:15.512582Z","shell.execute_reply":"2025-06-26T21:18:15.512599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from imblearn.under_sampling import TomekLinks\n\n#tl = TomekLinks(sampling_strategy='auto')  # Auto applies to all classes\n#X_tomek, y_tomek = tl.fit_resample(X, y)\n\n#  Verify Sizes\n#from collections import Counter\n#print(\"Original distribution:\", Counter(y))\n#print(\"Distribution after Tomek:\", Counter(y_tomek))","metadata":{"trusted":true,"id":"8OFMiC0nPD3i","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.513516Z","iopub.status.idle":"2025-06-26T21:18:15.513898Z","shell.execute_reply.started":"2025-06-26T21:18:15.513699Z","shell.execute_reply":"2025-06-26T21:18:15.513716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def extract_representatives_kmeans(X, y, n_samples_per_class=100):\n#     X_rep = []\n#     y_rep = []\n\n#     for label in np.unique(y):\n#         X_class = X[y == label]\n#         y_class = y[y == label]\n\n#         n_clusters = min(n_samples_per_class, len(X_class))\n\n#         kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n#         kmeans.fit(X_class)\n#         closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X_class)\n\n#         X_selected = X_class.iloc[closest]\n#         y_selected = y_class.iloc[closest]\n\n#         X_rep.append(X_selected)\n#         y_rep.append(y_selected)\n\n#     X_balanced_kmeans = pd.concat(X_rep)\n#     y_balanced_kmeans = pd.concat(y_rep)\n\n#     return X_balanced_kmeans, y_balanced_kmeans","metadata":{"trusted":true,"id":"0VvY6uhFPD3i","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.515040Z","iopub.status.idle":"2025-06-26T21:18:15.515547Z","shell.execute_reply.started":"2025-06-26T21:18:15.515383Z","shell.execute_reply":"2025-06-26T21:18:15.515400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply balancing by representativity\n#X_kmeans, y_kmeans = extract_representatives_kmeans(X, y, n_samples_per_class=100)\n\n# Split for training\n#X_train_km, X_test_km, y_train_km, y_test_km = train_test_split(\n#    X_kmeans, y_kmeans, test_size=0.2, stratify=y_kmeans, random_state=42\n#)\n\n# Train and evaluate models\n#for name, model in models.items():\n #   print(f\"\\n{name} with representative KMeans:\")\n #  model.fit(X_train_km, y_train_km)\n # y_pred_km = model.predict(X_test_km)\n #print(classification_report(y_test_km, y_pred_km))","metadata":{"trusted":true,"id":"yB30IKHJPD3i","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.516827Z","iopub.status.idle":"2025-06-26T21:18:15.517263Z","shell.execute_reply.started":"2025-06-26T21:18:15.517004Z","shell.execute_reply":"2025-06-26T21:18:15.517020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_full = pd.concat([X, y], axis=1)\n\n# df_sampled = df_full.groupby('IncidentGrade').apply(\n#     lambda g: g.sample(n=min(len(g), 100000), random_state=42)\n# ).reset_index(drop=True)\n\n# X_sampled = df_sampled.drop(columns='IncidentGrade')\n# y_sampled = df_sampled['IncidentGrade']\n\n# mini_kmeans = MiniBatchKMeans(n_init=10, batch_size=1024, max_iter=100, random_state=42)\n\n# cc = ClusterCentroids(estimator=mini_kmeans, random_state=42)\n\n# X_cc, y_cc = cc.fit_resample(X_sampled, y_sampled)\n\n# print(\"\\nClass distribution after ClusterCentroids:\")\n# print(pd.Series(y_cc).value_counts())\n\n# # Dividing to train and test\n# X_train_cc, X_test_cc, y_train_cc, y_test_cc = train_test_split(\n#     X_cc, y_cc, test_size=0.2, stratify=y_cc, random_state=42\n# )","metadata":{"trusted":true,"id":"TzLKIB3SPD3i","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.518306Z","iopub.status.idle":"2025-06-26T21:18:15.518636Z","shell.execute_reply.started":"2025-06-26T21:18:15.518445Z","shell.execute_reply":"2025-06-26T21:18:15.518461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"\\nModels after balancing:\")\n\n# for name, model in models.items():\n#     print(f\"\\n{name} with ClusterCentroids:\")\n#     model.fit(X_train_cc, y_train_cc)\n#     y_pred_cnn = model.predict(X_test_cc)\n#     print(f\"\\n{name} Classification Report:\")\n#     print(classification_report(y_test_cc, y_pred_cc))","metadata":{"trusted":true,"id":"JybUhUpxPD3k","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.519423Z","iopub.status.idle":"2025-06-26T21:18:15.519682Z","shell.execute_reply.started":"2025-06-26T21:18:15.519562Z","shell.execute_reply":"2025-06-26T21:18:15.519574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for name, model in models.items():\n#    print(f\"\\nTraining {name}...\")\n#    model.fit(X_train, y_train)\n#    y_pred = model.predict(X_test)\n#    print(f\"\\n{name} Classification Report:\")\n#    print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"id":"u5OMtdxMPD3k","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.520409Z","iopub.status.idle":"2025-06-26T21:18:15.520672Z","shell.execute_reply.started":"2025-06-26T21:18:15.520553Z","shell.execute_reply":"2025-06-26T21:18:15.520564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.5. Ensemble and Stacking","metadata":{"id":"VfnhI-oXPD3k","_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"# from sklearn.ensemble import VotingClassifier\n# from sklearn.ensemble import StackingClassifier\n# from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true,"id":"vpXrKM2lPD3l","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.521492Z","iopub.status.idle":"2025-06-26T21:18:15.521756Z","shell.execute_reply.started":"2025-06-26T21:18:15.521630Z","shell.execute_reply":"2025-06-26T21:18:15.521641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ensemble = VotingClassifier(\n#     estimators=[\n#         ('catboost', models['CatBoost']),\n#         ('xgboost', models['XGBoost']),\n#         ('randomforest', models['RandomForest'])\n#     ],\n#     voting='soft'\n# )\n\n# ensemble.fit(X_train, y_train)\n\n# y_pred_ensemble = ensemble.predict(X_test)\n# print(\"\\nEnsemble with Soft Voting on balanced data:\")\n# print(classification_report(y_test, y_pred_ensemble))","metadata":{"trusted":true,"id":"ifKDwd8oPD3l","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.523379Z","iopub.status.idle":"2025-06-26T21:18:15.523779Z","shell.execute_reply.started":"2025-06-26T21:18:15.523580Z","shell.execute_reply":"2025-06-26T21:18:15.523597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{"id":"lvbquRGsQFQs","_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"# # stacking_clf = StackingClassifier(\n# #     estimators=[\n# #         ('catboost', models['CatBoost']),\n# #         ('xgboost', models['XGBoost']),\n# #         ('randomforest', models['RandomForest'])\n# #     ],\n# #     final_estimator=LogisticRegression(max_iter=1000),\n# #     cv=5,\n# #     n_jobs=-1,\n# #     passthrough=False\n# # )\n\n# # stacking_clf.fit(X_train, y_train)\n\n# # y_pred_stack = stacking_clf.predict(X_test)\n# print(\"\\nEnsemble with Soft Voting on balanced data:\")\n# # print(classification_report(y_test, y_pred_stack))","metadata":{"trusted":true,"id":"6ggjV68DPD3m","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.526597Z","iopub.status.idle":"2025-06-26T21:18:15.527091Z","shell.execute_reply.started":"2025-06-26T21:18:15.526797Z","shell.execute_reply":"2025-06-26T21:18:15.526813Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Evaluation","metadata":{"id":"penS1KRjPD3n"}},{"cell_type":"markdown","source":"## 5.1 Non Balanced","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np","metadata":{"trusted":true,"id":"5hMDdFOXPD3o","execution":{"iopub.status.busy":"2025-06-26T21:18:15.528463Z","iopub.status.idle":"2025-06-26T21:18:15.528753Z","shell.execute_reply.started":"2025-06-26T21:18:15.528624Z","shell.execute_reply":"2025-06-26T21:18:15.528637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # # Binarize labels for multiclass classification\n# # classes = np.unique(y_test)\n# # y_test_bin = label_binarize(y_test, classes=classes)\n# # n_classes = y_test_bin.shape[1]\n\n# # # Get probabilities\n# # y_proba_ensemble = ensemble.predict_proba(X_test)\n# # # y_proba_stack = stacking_clf.predict_proba(X_test)\n\n# # Binarize labels for multiclass classification\n# classes = np.unique(y_test)\n# y_test_bin = label_binarize(y_test, classes=classes)\n# n_classes = y_test_bin.shape[1]","metadata":{"trusted":true,"id":"zYYusXkVPD3p","execution":{"iopub.status.busy":"2025-06-26T21:18:15.529712Z","iopub.status.idle":"2025-06-26T21:18:15.530015Z","shell.execute_reply.started":"2025-06-26T21:18:15.529856Z","shell.execute_reply":"2025-06-26T21:18:15.529867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.1. ROC - AUC Curve\n","metadata":{"id":"2G28IDBfPD3p"}},{"cell_type":"code","source":"# # # Calculate ROC curves and AUC for each class\n# # fpr_ens, tpr_ens, fpr_stack, tpr_stack, auc_ens, auc_stack = {}, {}, {}, {}, {}, {}\n# # for i in range(n_classes):\n# #     fpr_ens[i], tpr_ens[i], _ = roc_curve(y_test_bin[:, i], y_proba_ensemble[:, i])\n# #     # fpr_stack[i], tpr_stack[i], _ = roc_curve(y_test_bin[:, i], y_proba_stack[:, i])\n# #     auc_ens[i] = auc(fpr_ens[i], tpr_ens[i])\n# #     # auc_stack[i] = auc(fpr_stack[i], tpr_stack[i])\n\n# class_names = list(label_map.keys())  \n# for name, model in models.items():\n#     print(f\"\\nPlotting ROC curve for {name}...\")\n\n#     # Predict probabilities for each class\n#     y_score = model.predict_proba(X_test)\n\n#     # Compute ROC curve and ROC area for each class\n#     fpr = dict()\n#     tpr = dict()\n#     roc_auc = dict()\n\n#     for i in range(n_classes):\n#         fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n#         roc_auc[i] = auc(fpr[i], tpr[i])\n\n#     # Compute micro-average ROC curve and ROC area\n#     fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n#     roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n#     # Plot ROC curves\n#     plt.figure(figsize=(8, 6))\n#     plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n#              label=f'micro-average ROC (area = {roc_auc[\"micro\"]:.2f})',\n#              color='deeppink', linestyle=':', linewidth=4)\n\n#     colors = ['aqua', 'darkorange', 'cornflowerblue']\n#     for i, color in zip(range(n_classes), colors):\n#         plt.plot(fpr[i], tpr[i], color=color, lw=2,\n#                  label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n\n#     plt.plot([0, 1], [0, 1], 'k--', lw=2)\n#     plt.xlim([0.0, 1.0])\n#     plt.ylim([0.0, 1.05])\n#     plt.xlabel('False Positive Rate')\n#     plt.ylabel('True Positive Rate')\n#     plt.title(f'{name} - Multi-class ROC Curve')\n#     plt.legend(loc=\"lower right\")\n#     plt.grid(True)\n#     plt.show()","metadata":{"trusted":true,"id":"t-DL1hayPD3s","execution":{"iopub.status.busy":"2025-06-26T21:18:15.531442Z","iopub.status.idle":"2025-06-26T21:18:15.531776Z","shell.execute_reply.started":"2025-06-26T21:18:15.531589Z","shell.execute_reply":"2025-06-26T21:18:15.531600Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.2. Confusion matrix","metadata":{"id":"8O8SIendPD3t"}},{"cell_type":"code","source":"# # # Confusion matrix - Ensemble\n# # cm_ens = confusion_matrix(y_test, y_pred_ensemble)\n# # disp_ens = ConfusionMatrixDisplay(confusion_matrix=cm_ens, display_labels=classes)\n# # disp_ens.plot(cmap=plt.cm.Blues)\n# # plt.title(\"Confusion matrix - Ensemble\")\n# # plt.show()\n\n# # # Confusion matrix - Stacking\n# # # cm_stack = confusion_matrix(y_test, y_pred_stack)\n# # # disp_stack = ConfusionMatrixDisplay(confusion_matrix=cm_stack, display_labels=classes)\n# # # disp_stack.plot(cmap=plt.cm.Oranges)\n# # # plt.title(\"Confusion matrix - Stacking\")\n# # # plt.show()\n# class_names = list(label_map.keys())  \n# for name, model in models.items():\n#     print(f\"\\nConfusion matrix - {name}\")\n    \n#     y_pred = model.predict(X_test)\n#     cm = confusion_matrix(y_test, y_pred)\n#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    \n#     # Custom colormap per model (optional)\n#     cmap = plt.cm.Blues if name == 'CatBoost' else (plt.cm.Oranges if name == 'XGBoost' else plt.cm.Greens)\n    \n#     disp.plot(cmap=cmap)\n#     plt.title(f\"Confusion Matrix - {name}\")\n#     plt.show()","metadata":{"trusted":true,"id":"wMTXd11-PD3t","execution":{"iopub.status.busy":"2025-06-26T21:18:15.532853Z","iopub.status.idle":"2025-06-26T21:18:15.533206Z","shell.execute_reply.started":"2025-06-26T21:18:15.533032Z","shell.execute_reply":"2025-06-26T21:18:15.533051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3. Precision, Recall, F1-Score","metadata":{"id":"N5A07ijmPD3u"}},{"cell_type":"code","source":"# for name, model in loaded_models.items():\n#     print(f\"\\n{name} Classification Report:\")\n#     print(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T21:18:15.534472Z","iopub.status.idle":"2025-06-26T21:18:15.534721Z","shell.execute_reply.started":"2025-06-26T21:18:15.534606Z","shell.execute_reply":"2025-06-26T21:18:15.534617Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.4. Distribution of Predicted Probabilities by Class","metadata":{"id":"VxF8O3W-PD3u"}},{"cell_type":"code","source":"# import seaborn as sns\n# import pandas as pd","metadata":{"trusted":true,"id":"txZiXNCMPD3u","execution":{"iopub.status.busy":"2025-06-26T21:18:15.535826Z","iopub.status.idle":"2025-06-26T21:18:15.536136Z","shell.execute_reply.started":"2025-06-26T21:18:15.536003Z","shell.execute_reply":"2025-06-26T21:18:15.536020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for name, model in models.items():\n#     print(f\"\\nPlotting predicted probability distributions for: {name}\")\n\n#     # Get predicted probabilities\n#     y_proba = model.predict_proba(X_test)\n\n#     # Create DataFrame with probabilities and true class\n#     proba_df = pd.DataFrame(y_proba, columns=class_names)\n#     proba_df['True Class'] = y_test.replace({v: k for k, v in label_map.items()})  # Map 0→'BenignPositive', etc.\n\n#     # Step 2: Plot KDE for each class\n#     for class_name in class_names:\n#         plt.figure(figsize=(8, 4))\n#         sns.kdeplot(\n#             data=proba_df, x=class_name, hue='True Class',\n#             common_norm=False, fill=True, alpha=0.4, linewidth=1.5,\n#             palette='tab10'\n#         )\n#         plt.title(f'{name} - Predicted Probability for Class: {class_name}')\n#         plt.xlabel('Predicted Probability')\n#         plt.ylabel('Density')\n#         plt.xlim(0, 1)\n#         plt.grid(True)\n#         plt.show()","metadata":{"trusted":true,"id":"XOOG2DaDPD3u"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.1 Balanced","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np","metadata":{"trusted":true,"id":"5hMDdFOXPD3o"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Binarize labels for multiclass classification\n# classes = np.unique(y_test)\n# y_test_bin = label_binarize(y_test, classes=classes)\n# n_classes = y_test_bin.shape[1]\n\n# # Get probabilities\n# y_proba_ensemble = ensemble.predict_proba(X_test)\n# # y_proba_stack = stacking_clf.predict_proba(X_test)\n\n# Binarize labels for multiclass classification\nclasses = np.unique(y_test)\ny_test_bin = label_binarize(y_test, classes=classes)\nn_classes = y_test_bin.shape[1]","metadata":{"trusted":true,"id":"zYYusXkVPD3p"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.1. ROC - AUC Curve\n","metadata":{"id":"2G28IDBfPD3p"}},{"cell_type":"code","source":"# # Calculate ROC curves and AUC for each class\n# fpr_ens, tpr_ens, fpr_stack, tpr_stack, auc_ens, auc_stack = {}, {}, {}, {}, {}, {}\n# for i in range(n_classes):\n#     fpr_ens[i], tpr_ens[i], _ = roc_curve(y_test_bin[:, i], y_proba_ensemble[:, i])\n#     # fpr_stack[i], tpr_stack[i], _ = roc_curve(y_test_bin[:, i], y_proba_stack[:, i])\n#     auc_ens[i] = auc(fpr_ens[i], tpr_ens[i])\n#     # auc_stack[i] = auc(fpr_stack[i], tpr_stack[i])\n\nclass_names = list(label_map.keys())  \nfor name, model in models_balanced.items():\n    print(f\"\\nPlotting ROC curve for {name}...\")\n\n    # Predict probabilities for each class\n    y_score = model.predict_proba(X_test)\n\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n    # Plot ROC curves\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label=f'micro-average ROC (area = {roc_auc[\"micro\"]:.2f})',\n             color='deeppink', linestyle=':', linewidth=4)\n\n    colors = ['aqua', 'darkorange', 'cornflowerblue']\n    for i, color in zip(range(n_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n                 label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'{name} - Multi-class ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true,"id":"t-DL1hayPD3s"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.2. Confusion matrix","metadata":{"id":"8O8SIendPD3t"}},{"cell_type":"code","source":"# # Confusion matrix - Ensemble\n# cm_ens = confusion_matrix(y_test, y_pred_ensemble)\n# disp_ens = ConfusionMatrixDisplay(confusion_matrix=cm_ens, display_labels=classes)\n# disp_ens.plot(cmap=plt.cm.Blues)\n# plt.title(\"Confusion matrix - Ensemble\")\n# plt.show()\n\n# # Confusion matrix - Stacking\n# # cm_stack = confusion_matrix(y_test, y_pred_stack)\n# # disp_stack = ConfusionMatrixDisplay(confusion_matrix=cm_stack, display_labels=classes)\n# # disp_stack.plot(cmap=plt.cm.Oranges)\n# # plt.title(\"Confusion matrix - Stacking\")\n# # plt.show()\nclass_names = list(label_map.keys())  \nfor name, model in models_balanced.items():\n    print(f\"\\nConfusion matrix - {name}\")\n    \n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    \n    # Custom colormap per model (optional)\n    cmap = plt.cm.Blues if name == 'CatBoost' else (plt.cm.Oranges if name == 'XGBoost' else plt.cm.Greens)\n    \n    disp.plot(cmap=cmap)\n    plt.title(f\"Confusion Matrix - {name}\")\n    plt.show()","metadata":{"trusted":true,"id":"wMTXd11-PD3t"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3. Precision, Recall, F1-Score","metadata":{"id":"N5A07ijmPD3u"}},{"cell_type":"code","source":"for name, model in models_loaded.items():\n    print(f\"\\n{name} Classification Report:\")\n    print(classification_report(y_test, y_pred))\n\nfor name, model in models_balanced.items():\n    print(f\"\\n{name} Classification Report:\")\n    print(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.4. Distribution of Predicted Probabilities by Class","metadata":{"id":"VxF8O3W-PD3u"}},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd","metadata":{"trusted":true,"id":"txZiXNCMPD3u"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name, model in models_balanced.items():\n    print(f\"\\nPlotting predicted probability distributions for: {name}\")\n\n    # Get predicted probabilities\n    y_proba = model.predict_proba(X_test)\n\n    # Create DataFrame with probabilities and true class\n    proba_df = pd.DataFrame(y_proba, columns=class_names)\n    proba_df['True Class'] = y_test.replace({v: k for k, v in label_map.items()})  # Map 0→'BenignPositive', etc.\n\n    # Step 2: Plot KDE for each class\n    for class_name in class_names:\n        plt.figure(figsize=(8, 4))\n        sns.kdeplot(\n            data=proba_df, x=class_name, hue='True Class',\n            common_norm=False, fill=True, alpha=0.4, linewidth=1.5,\n            palette='tab10'\n        )\n        plt.title(f'{name} - Predicted Probability for Class: {class_name}')\n        plt.xlabel('Predicted Probability')\n        plt.ylabel('Density')\n        plt.xlim(0, 1)\n        plt.grid(True)\n        plt.show()","metadata":{"trusted":true,"id":"XOOG2DaDPD3u"},"outputs":[],"execution_count":null}]}